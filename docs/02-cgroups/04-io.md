# 04 I/O Controller

## Goal

Set I/O bandwidth limits for a cgroup using `io.max`. You will learn how to throttle disk read/write speeds for processes, which is essential for preventing noisy-neighbor problems in multi-tenant systems.

## Prereqs

- Completed `03-cpu.md`
- A block device available for testing (physical disk, loop device, or device mapper)
- `sudo` access

## Concepts

### Why I/O Limits Matter

Consider a shared server where one user runs a backup script that saturates the disk. Without I/O limits, every other user experiences sluggish performance. The cgroup v2 I/O controller lets you set per-cgroup bandwidth and IOPS limits on specific block devices.

### The io.max Format

The `io.max` file uses a device-specific format:

```
MAJ:MIN rbps=BYTES wbps=BYTES riops=OPS wiops=OPS
```

Where:
- **MAJ:MIN**: The device's major and minor numbers (e.g., `8:0` for `/dev/sda`)
- **rbps**: Maximum read bytes per second
- **wbps**: Maximum write bytes per second
- **riops**: Maximum read I/O operations per second
- **wiops**: Maximum write I/O operations per second
- **max**: Special value meaning "unlimited" for any parameter

Example entries:
```
8:0 rbps=1048576 wbps=1048576
8:0 rbps=max wbps=524288 riops=100 wiops=100
```

### Finding Device Major:Minor Numbers

Block devices have unique major:minor identifiers. Here is how to find them:

```bash
# List all block devices with their major:minor numbers
lsblk -d -o NAME,MAJ:MIN,TYPE,SIZE

# Example output:
# NAME MAJ:MIN TYPE  SIZE
# sda    8:0   disk   20G
# vda  254:0   disk   50G
# loop0  7:0   loop  100M

# Or read directly from sysfs
cat /sys/block/sda/dev
# Output: 8:0
```

### io.stat: Monitoring I/O Statistics

The `io.stat` file shows current I/O statistics per device:

```bash
cat /sys/fs/cgroup/my-cgroup/io.stat
# 8:0 rbytes=1048576 wbytes=2097152 rios=100 wios=200 dbytes=0 dios=0
```

Fields:
- **rbytes/wbytes**: Total bytes read/written
- **rios/wios**: Total read/write operations
- **dbytes/dios**: Discard bytes and operations

### Important Limitations

1. **Block devices only**: I/O limits work on block devices (disks, loop devices). They do NOT work on:
   - tmpfs (memory-backed)
   - overlayfs (used by containers)
   - Network filesystems (NFS, CIFS)

2. **Direct I/O is more predictable**: Buffered I/O goes through the page cache, so throttling behavior can be less immediate.

3. **Controller must be enabled**: The io controller must be enabled in the cgroup's `cgroup.subtree_control`.

## Write Tests (Red)

Before implementing the `io-max` subcommand, you need to add the command variant and create the test file.

### Step 1: Add the IoMax Command Variant

**File**: `crates/cgroup-tool/src/main.rs`

Add a new variant to the `Command` enum after `PidsMax`:

```rust
#[derive(Subcommand)]
enum Command {
    Create { path: String },
    Delete { path: String },
    Attach { path: String, pid: u32 },
    MemoryMax { path: String, bytes: u64 },
    CpuMax { path: String, quota: String },
    PidsMax { path: String, max: u64 },
    // Add this new variant:
    IoMax {
        path: String,
        /// Device major:minor (e.g., "8:0")
        device: String,
        /// I/O limit specification (e.g., "rbps=1048576 wbps=1048576")
        limit: String,
    },
}
```

Add a placeholder match arm in the `main()` function:

```rust
// TODO: Implement I/O limit setting
// Lesson: docs/02-cgroups/04-io.md
// Tests: tests/io_test.rs
//
// TDD Steps:
// 1. Write tests in tests/io_test.rs (RED)
// 2. Implement this function (GREEN)
// 3. Refactor as needed
//
// Implementation hints:
// - Write to /sys/fs/cgroup/{path}/io.max
// - Format: "MAJ:MIN rbps=X wbps=X riops=X wiops=X"
// - Example: "8:0 rbps=1048576 wbps=1048576"
// - Can use "max" for unlimited
// - Verify io controller is enabled in subtree_control
Command::IoMax { path, device, limit } => {
    todo!("Implement I/O limit - write tests first! (path: {path}, device: {device}, limit: {limit})")
}
```

### Step 2: Create the Test File

**File**: `crates/cgroup-tool/tests/io_test.rs`

Create a new test file with the following content:

```rust
// Tests for the `io-max` subcommand (I/O bandwidth limits)
// Lesson: docs/02-cgroups/04-io.md
//
// TDD Workflow:
// 1. Write the test(s) below FIRST (RED - they will fail)
// 2. Implement the code in src/main.rs to make tests pass (GREEN)
// 3. Refactor as needed
//
// NOTE: These tests require cgroup v2, a block device, and appropriate permissions.
// Run with: sudo -E cargo test -p cgroup-tool --test io_test

use std::fs;
use std::path::Path;

// Helper to get a valid block device for testing
// Returns None if no suitable device is found
fn find_test_block_device() -> Option<String> {
    // Try common block device paths
    let candidates = ["/sys/block/sda", "/sys/block/vda", "/sys/block/nvme0n1"];

    for candidate in candidates {
        if Path::new(candidate).exists() {
            if let Ok(dev) = fs::read_to_string(format!("{}/dev", candidate)) {
                return Some(dev.trim().to_string());
            }
        }
    }

    // Try to find any block device
    if let Ok(entries) = fs::read_dir("/sys/block") {
        for entry in entries.flatten() {
            let name = entry.file_name();
            let name_str = name.to_string_lossy();
            // Skip loop devices without backing files and ram devices
            if name_str.starts_with("loop") || name_str.starts_with("ram") {
                continue;
            }
            let dev_path = entry.path().join("dev");
            if let Ok(dev) = fs::read_to_string(&dev_path) {
                return Some(dev.trim().to_string());
            }
        }
    }

    None
}

#[test]
fn test_set_io_limit() {
    // TODO: Write a test that verifies setting I/O bandwidth limit
    //
    // Hints:
    // - io.max format is "MAJ:MIN rbps=X wbps=X riops=X wiops=X"
    // - Need a real block device's major:minor number
    // - Use find_test_block_device() helper to get a valid device
    // - Verify io.max contains the correct limit after setting
    //
    // Test approach:
    // 1. Find a block device using find_test_block_device()
    // 2. Create test cgroup
    // 3. Enable io controller (write "+io" to parent's cgroup.subtree_control)
    // 4. Run `cgroup-tool io-max io-test "8:0" "rbps=1048576 wbps=1048576"`
    // 5. Verify /sys/fs/cgroup/io-test/io.max contains the expected line
    // 6. Clean up
    //
    // Example assertion:
    // let io_max = fs::read_to_string("/sys/fs/cgroup/io-test/io.max")?;
    // assert!(io_max.contains("8:0 rbps=1048576 wbps=1048576"));

    todo!("Implement test for setting I/O bandwidth limit")
}

#[test]
#[ignore] // Remove this attribute after implementing the test
fn test_io_limit_with_iops() {
    // TODO: Write a test that sets both bandwidth and IOPS limits
    //
    // Hints:
    // - Can combine all limit types: rbps, wbps, riops, wiops
    // - Example: "rbps=1048576 wbps=1048576 riops=100 wiops=100"
    // - All unspecified limits remain at "max" (unlimited)

    todo!("Implement test for combined bandwidth and IOPS limits")
}

#[test]
#[ignore] // Remove this attribute after implementing the test
fn test_io_limit_enforcement() {
    // TODO: Write a test that verifies I/O limit is enforced
    //
    // Hints:
    // - Create cgroup with low write bandwidth (e.g., 1MB/s)
    // - Use dd with direct I/O to write data
    // - Measure time taken - should be throttled
    // - Can check io.stat for bytes written
    //
    // Example dd command:
    // dd if=/dev/zero of=/tmp/testfile bs=1M count=5 oflag=direct
    //
    // With 1MB/s limit, writing 5MB should take ~5 seconds

    todo!("Implement integration test for I/O limit enforcement")
}

#[test]
#[ignore] // Remove this attribute after implementing the test
fn test_io_stat_tracking() {
    // TODO: Write a test that verifies io.stat tracks I/O usage
    //
    // Hints:
    // - Attach a process to cgroup
    // - Process performs I/O operations
    // - io.stat should show rbytes/wbytes increasing
    // - Read io.stat before and after I/O to compare

    todo!("Implement test for I/O statistics tracking")
}

#[test]
#[ignore] // Remove this attribute after implementing the test
fn test_io_max_remove_limit() {
    // TODO: Write a test that verifies removing I/O limit
    //
    // Hints:
    // - Setting all values to "max" removes limits for that device
    // - Example: "8:0 rbps=max wbps=max riops=max wiops=max"
    // - Or simply not specifying a device removes its entry

    todo!("Implement test for removing I/O limit")
}

#[test]
fn test_io_max_invalid_device() {
    // TODO: Write a test for invalid device handling
    //
    // Hints:
    // - Using a non-existent device should fail gracefully
    // - Invalid format (not MAJ:MIN) should be rejected
    // - The kernel returns an error for invalid devices

    todo!("Implement test for invalid device error handling")
}
```

### Step 3: Run Tests (Expect Failure)

```bash
# First, verify the code compiles
cargo build -p cgroup-tool

# Run the io tests (they will fail - this is expected)
sudo -E cargo test -p cgroup-tool --test io_test
```

Expected output: Tests fail with `todo!()` panic or because implementation is missing. This is the RED phase.

## Build (Green)

**Implementation file**: `crates/cgroup-tool/src/main.rs`
**TODO location**: The `Command::IoMax` match arm you added

### Step 1: Implement the IoMax Handler

Replace the `todo!()` with the actual implementation:

```rust
Command::IoMax { path, device, limit } => {
    // Construct the full path to the io.max file
    let cgroup_path = if path.starts_with('/') {
        format!("/sys/fs/cgroup{}/io.max", path)
    } else {
        format!("/sys/fs/cgroup/{}/io.max", path)
    };

    // Format: "MAJ:MIN limit_spec"
    // Example: "8:0 rbps=1048576 wbps=1048576"
    let io_max_content = format!("{} {}\n", device, limit);

    // Write the limit to io.max
    std::fs::write(&cgroup_path, &io_max_content)
        .with_context(|| format!("Failed to write I/O limit to {}", cgroup_path))?;

    println!(
        "Set I/O limit for device {} in cgroup {}: {}",
        device, path, limit
    );

    Ok(())
}
```

### Step 2: Run Tests (Expect Success)

```bash
# Run the tests again
sudo -E cargo test -p cgroup-tool --test io_test

# If test_set_io_limit passes, you are GREEN
```

### Implementation Notes

The implementation is straightforward because the kernel does the heavy lifting:

1. **Validation**: The kernel validates the device major:minor and limit format. Invalid values return an error.
2. **Multiple devices**: You can set limits for multiple devices by writing multiple lines or making multiple calls.
3. **Updating limits**: Writing a new limit for the same device replaces the previous one.

## Verify

### Automated Verification

```bash
cargo test -p cgroup-tool --test io_test
```

### Manual Verification

First, find an available block device:

```bash
# List block devices
lsblk -d -o NAME,MAJ:MIN,TYPE,SIZE

# Example output:
# NAME    MAJ:MIN TYPE  SIZE
# sda       8:0   disk   20G
# loop0     7:0   loop  100M

# Note the MAJ:MIN for your device (e.g., 8:0 for sda)
```

Create a cgroup and set I/O limits:

```bash
# Create a test cgroup
sudo mkdir -p /sys/fs/cgroup/io-test

# Enable the io controller (required for io.max to work)
# Note: This writes to the PARENT's subtree_control
echo "+io" | sudo tee /sys/fs/cgroup/cgroup.subtree_control

# Verify io controller is enabled
cat /sys/fs/cgroup/cgroup.controllers
# Should include: io

# Set I/O limit (1MB/s read and write) - adjust device as needed
sudo cargo run -q -p cgroup-tool -- io-max io-test "8:0" "rbps=1048576 wbps=1048576"

# Verify the limit was set
cat /sys/fs/cgroup/io-test/io.max
# Should show: 8:0 rbps=1048576 wbps=1048576
```

### Testing I/O Throttling

To actually observe throttling, you need to run I/O within the cgroup:

```bash
# Attach current shell to the cgroup
echo $$ | sudo tee /sys/fs/cgroup/io-test/cgroup.procs

# Now I/O from this shell is throttled
# Use dd with direct I/O to bypass page cache
# Writing 5MB at 1MB/s should take ~5 seconds
time dd if=/dev/zero of=/tmp/testfile bs=1M count=5 oflag=direct 2>&1

# Expected: real time should be approximately 5 seconds
# Without throttling, this would complete in milliseconds
```

Check I/O statistics:

```bash
# View I/O stats for the cgroup
cat /sys/fs/cgroup/io-test/io.stat
# Shows: 8:0 rbytes=... wbytes=... rios=... wios=...
```

### Verifying with IOPS Limits

```bash
# Set IOPS limit (100 write operations per second)
sudo cargo run -q -p cgroup-tool -- io-max io-test "8:0" "wiops=100"

# Verify
cat /sys/fs/cgroup/io-test/io.max
# Should show: 8:0 wiops=100
```

## Clean Up

```bash
# Move current shell back to root cgroup first
echo $$ | sudo tee /sys/fs/cgroup/cgroup.procs

# Remove test file
rm -f /tmp/testfile

# Delete the test cgroup
sudo rmdir /sys/fs/cgroup/io-test

# Verify removal
ls /sys/fs/cgroup/io-test 2>&1 || echo "Cgroup removed successfully"
```

## Common Errors

### 1. "No such file or directory" when writing to io.max

**Cause**: The io controller is not enabled for the cgroup.

**Fix**: Enable the io controller in the parent cgroup's `cgroup.subtree_control`:
```bash
echo "+io" | sudo tee /sys/fs/cgroup/cgroup.subtree_control
```

### 2. "Invalid argument" when setting limit

**Cause**: The device major:minor is invalid, or the limit format is incorrect.

**Fix**:
- Verify the device exists: `lsblk -d -o NAME,MAJ:MIN`
- Check limit format: use `rbps=N` not `rbps:N`
- Ensure values are valid numbers or "max"

### 3. "Operation not permitted" on containerized environments

**Cause**: The I/O controller may not work on overlayfs or within containers that lack access to the underlying block device.

**Fix**:
- Test on a host system with direct block device access
- Use a loop device with a backing file on a real filesystem:
  ```bash
  dd if=/dev/zero of=/tmp/loopfile bs=1M count=100
  sudo losetup /dev/loop0 /tmp/loopfile
  # Now use 7:0 as the device
  ```

### 4. I/O throttling not observed

**Cause**: Buffered I/O goes through the page cache and may not be immediately throttled.

**Fix**: Use direct I/O to bypass the page cache:
```bash
dd if=/dev/zero of=/tmp/testfile bs=1M count=5 oflag=direct
```
Or use O_DIRECT flag in your programs.

### 5. "Device or resource busy" when deleting cgroup

**Cause**: Processes are still attached to the cgroup.

**Fix**: Move all processes out before deletion:
```bash
# Find attached processes
cat /sys/fs/cgroup/io-test/cgroup.procs

# Move them to root cgroup
for pid in $(cat /sys/fs/cgroup/io-test/cgroup.procs); do
    echo $pid | sudo tee /sys/fs/cgroup/cgroup.procs
done

# Now delete
sudo rmdir /sys/fs/cgroup/io-test
```

## Notes

- The io controller only affects block I/O. Network I/O uses different mechanisms (tc, eBPF).
- Setting `rbps=0` or `wbps=0` effectively blocks all read or write I/O to that device.
- Multiple devices can have limits in the same cgroup (one line per device in io.max).
- The `io.weight` file provides proportional I/O scheduling rather than hard limits.
- For production use, consider using `io.latency` for latency-based I/O control.
- See `Documentation/admin-guide/cgroup-v2.rst` in the Linux kernel source for complete documentation.

## Summary

In this lesson you learned:
- The `io.max` format: `MAJ:MIN rbps=X wbps=X riops=X wiops=X`
- How to find device major:minor numbers using `lsblk` or `/sys/block/*/dev`
- The difference between bandwidth limits (rbps/wbps) and IOPS limits (riops/wiops)
- How to verify I/O throttling using `dd` with direct I/O
- That I/O limits only work on block devices, not tmpfs or overlayfs

## Next

`05-pids.md` - Limit the number of processes in a cgroup to prevent fork bombs.
