# 04 I/O Controller

## Goal

Set I/O bandwidth limits for a cgroup using `io.max`. You will learn how to throttle disk read/write speeds for processes, which is essential for preventing noisy-neighbor problems in multi-tenant systems.

## Prereqs

- Completed `03-cpu.md`
- A block device available for testing (physical disk, loop device, or device mapper)
- `sudo` access

## Concepts

### Why I/O Limits Matter

Consider a shared server where one user runs a backup script that saturates the disk. Without I/O limits, every other user experiences sluggish performance. The cgroup v2 I/O controller lets you set per-cgroup bandwidth and IOPS limits on specific block devices.

### The io.max Format

The `io.max` file uses a device-specific format:

```
MAJ:MIN rbps=BYTES wbps=BYTES riops=OPS wiops=OPS
```

Where:
- **MAJ:MIN**: The device's major and minor numbers (e.g., `8:0` for `/dev/sda`)
- **rbps**: Maximum read bytes per second
- **wbps**: Maximum write bytes per second
- **riops**: Maximum read I/O operations per second
- **wiops**: Maximum write I/O operations per second
- **max**: Special value meaning "unlimited" for any parameter

Example entries:
```
8:0 rbps=1048576 wbps=1048576
8:0 rbps=max wbps=524288 riops=100 wiops=100
```

### Finding Device Major:Minor Numbers

Block devices have unique major:minor identifiers. Here is how to find them:

```bash
# List all block devices with their major:minor numbers
lsblk -d -o NAME,MAJ:MIN,TYPE,SIZE

# Example output:
# NAME MAJ:MIN TYPE  SIZE
# sda    8:0   disk   20G
# vda  254:0   disk   50G
# loop0  7:0   loop  100M

# Or read directly from sysfs
cat /sys/block/sda/dev
# Output: 8:0
```

### io.stat: Monitoring I/O Statistics

The `io.stat` file shows current I/O statistics per device:

```bash
cat /sys/fs/cgroup/my-cgroup/io.stat
# 8:0 rbytes=1048576 wbytes=2097152 rios=100 wios=200 dbytes=0 dios=0
```

Fields:
- **rbytes/wbytes**: Total bytes read/written
- **rios/wios**: Total read/write operations
- **dbytes/dios**: Discard bytes and operations

### Important Limitations

1. **Block devices only**: I/O limits work on block devices (disks, loop devices). They do NOT work on:
   - tmpfs (memory-backed)
   - overlayfs (used by containers)
   - Network filesystems (NFS, CIFS)

2. **Direct I/O is more predictable**: Buffered I/O goes through the page cache, so throttling behavior can be less immediate.

3. **Controller must be enabled**: The io controller must be enabled in the cgroup's `cgroup.subtree_control`.

## Write Tests (Red)

The test file and command scaffold already exist. Your task is to implement the test functions.

### Step 1: Open the Test File

**File**: `crates/cgroup-tool/tests/io_test.rs`

This file already exists with test function stubs containing `todo!()` macros. Each test has helpful comments explaining what it should verify.

### Step 2: Implement the Test Functions

Replace the `todo!()` calls in the test file with actual test implementations. Start with the simpler tests:

- **test_set_io_limit**: Verify basic I/O limit setting (no `#[ignore]` attribute)
- **test_io_max_invalid_device**: Verify error handling for invalid devices (no `#[ignore]` attribute)
- Other tests: Remove `#[ignore]` attribute when implementing

Each test includes hints in its comments. Example approach for `test_set_io_limit`:
1. Find a block device using the `find_test_block_device()` helper
2. Create test cgroup at `/sys/fs/cgroup/io-test`
3. Enable io controller: `echo "+io" | sudo tee /sys/fs/cgroup/cgroup.subtree_control`
4. Run the `cgroup-tool io-max` subcommand
5. Verify the limit is set by reading `/sys/fs/cgroup/io-test/io.max`
6. Clean up the test cgroup

### Step 3: Run Tests (Expect Failure)

```bash
# First, verify the code compiles
cargo build -p cgroup-tool

# Run the io tests (they will fail - this is expected)
sudo -E cargo test -p cgroup-tool --test io_test
```

Expected output: Tests fail with `todo!()` panic or because implementation is missing. This is the RED phase.

## Build (Green)

**Implementation file**: `crates/cgroup-tool/src/main.rs`

The `Command::IoMax` variant already exists in the enum (lines 36-43). Your task is to implement the handler in the match statement.

### Step 1: Open the Existing IoMax Match Arm

The match arm exists but contains a `todo!()` placeholder. Find it in the `main()` function (around line 172):

```rust
Command::IoMax { path, device, limit } => {
    todo!("Implement I/O limit - write tests first! (path: {path}, device: {device}, limit: {limit})")
}
```

### Step 2: Implement the IoMax Handler

Replace the `todo!()` with the actual implementation:

```rust
Command::IoMax { path, device, limit } => {
    // Construct the full path to the io.max file
    let cgroup_path = if path.starts_with('/') {
        format!("/sys/fs/cgroup{}/io.max", path)
    } else {
        format!("/sys/fs/cgroup/{}/io.max", path)
    };

    // Format: "MAJ:MIN limit_spec"
    // Example: "8:0 rbps=1048576 wbps=1048576"
    let io_max_content = format!("{} {}\n", device, limit);

    // Write the limit to io.max
    std::fs::write(&cgroup_path, &io_max_content)
        .with_context(|| format!("Failed to write I/O limit to {}", cgroup_path))?;

    println!(
        "Set I/O limit for device {} in cgroup {}: {}",
        device, path, limit
    );

    Ok(())
}
```

### Step 3: Run Tests (Expect Success)

```bash
# Run the tests again
sudo -E cargo test -p cgroup-tool --test io_test

# If test_set_io_limit passes, you are GREEN
```

### Implementation Notes

The implementation is straightforward because the kernel does the heavy lifting:

1. **Validation**: The kernel validates the device major:minor and limit format. Invalid values return an error.
2. **Multiple devices**: You can set limits for multiple devices by writing multiple lines or making multiple calls.
3. **Updating limits**: Writing a new limit for the same device replaces the previous one.

## Verify

### Automated Verification

```bash
cargo test -p cgroup-tool --test io_test
```

### Manual Verification

First, find an available block device:

```bash
# List block devices
lsblk -d -o NAME,MAJ:MIN,TYPE,SIZE

# Example output:
# NAME    MAJ:MIN TYPE  SIZE
# sda       8:0   disk   20G
# loop0     7:0   loop  100M

# Note the MAJ:MIN for your device (e.g., 8:0 for sda)
```

Create a cgroup and set I/O limits:

```bash
# Create a test cgroup
sudo mkdir -p /sys/fs/cgroup/io-test

# Enable the io controller (required for io.max to work)
# Note: This writes to the PARENT's subtree_control
echo "+io" | sudo tee /sys/fs/cgroup/cgroup.subtree_control

# Verify io controller is enabled
cat /sys/fs/cgroup/cgroup.controllers
# Should include: io

# Set I/O limit (1MB/s read and write) - adjust device as needed
sudo cargo run -q -p cgroup-tool -- io-max io-test "8:0" "rbps=1048576 wbps=1048576"

# Verify the limit was set
cat /sys/fs/cgroup/io-test/io.max
# Should show: 8:0 rbps=1048576 wbps=1048576
```

### Testing I/O Throttling

To actually observe throttling, you need to run I/O within the cgroup:

```bash
# Attach current shell to the cgroup
echo $$ | sudo tee /sys/fs/cgroup/io-test/cgroup.procs

# Now I/O from this shell is throttled
# Use dd with direct I/O to bypass page cache
# Writing 5MB at 1MB/s should take ~5 seconds
time dd if=/dev/zero of=/tmp/testfile bs=1M count=5 oflag=direct 2>&1

# Expected: real time should be approximately 5 seconds
# Without throttling, this would complete in milliseconds
```

Check I/O statistics:

```bash
# View I/O stats for the cgroup
cat /sys/fs/cgroup/io-test/io.stat
# Shows: 8:0 rbytes=... wbytes=... rios=... wios=...
```

### Verifying with IOPS Limits

```bash
# Set IOPS limit (100 write operations per second)
sudo cargo run -q -p cgroup-tool -- io-max io-test "8:0" "wiops=100"

# Verify
cat /sys/fs/cgroup/io-test/io.max
# Should show: 8:0 wiops=100
```

## Clean Up

```bash
# Move current shell back to root cgroup first
echo $$ | sudo tee /sys/fs/cgroup/cgroup.procs

# Remove test file
rm -f /tmp/testfile

# Delete the test cgroup
sudo rmdir /sys/fs/cgroup/io-test

# Verify removal
ls /sys/fs/cgroup/io-test 2>&1 || echo "Cgroup removed successfully"
```

## Common Errors

### 1. "No such file or directory" when writing to io.max

**Cause**: The io controller is not enabled for the cgroup.

**Fix**: Enable the io controller in the parent cgroup's `cgroup.subtree_control`:
```bash
echo "+io" | sudo tee /sys/fs/cgroup/cgroup.subtree_control
```

### 2. "Invalid argument" when setting limit

**Cause**: The device major:minor is invalid, or the limit format is incorrect.

**Fix**:
- Verify the device exists: `lsblk -d -o NAME,MAJ:MIN`
- Check limit format: use `rbps=N` not `rbps:N`
- Ensure values are valid numbers or "max"

### 3. "Operation not permitted" on containerized environments

**Cause**: The I/O controller may not work on overlayfs or within containers that lack access to the underlying block device.

**Fix**:
- Test on a host system with direct block device access
- Use a loop device with a backing file on a real filesystem:
  ```bash
  dd if=/dev/zero of=/tmp/loopfile bs=1M count=100
  sudo losetup /dev/loop0 /tmp/loopfile
  # Now use 7:0 as the device
  ```

### 4. I/O throttling not observed

**Cause**: Buffered I/O goes through the page cache and may not be immediately throttled.

**Fix**: Use direct I/O to bypass the page cache:
```bash
dd if=/dev/zero of=/tmp/testfile bs=1M count=5 oflag=direct
```
Or use O_DIRECT flag in your programs.

### 5. "Device or resource busy" when deleting cgroup

**Cause**: Processes are still attached to the cgroup.

**Fix**: Move all processes out before deletion:
```bash
# Find attached processes
cat /sys/fs/cgroup/io-test/cgroup.procs

# Move them to root cgroup
for pid in $(cat /sys/fs/cgroup/io-test/cgroup.procs); do
    echo $pid | sudo tee /sys/fs/cgroup/cgroup.procs
done

# Now delete
sudo rmdir /sys/fs/cgroup/io-test
```

## Notes

- The io controller only affects block I/O. Network I/O uses different mechanisms (tc, eBPF).
- Setting `rbps=0` or `wbps=0` effectively blocks all read or write I/O to that device.
- Multiple devices can have limits in the same cgroup (one line per device in io.max).
- The `io.weight` file provides proportional I/O scheduling rather than hard limits.
- For production use, consider using `io.latency` for latency-based I/O control.
- See `Documentation/admin-guide/cgroup-v2.rst` in the Linux kernel source for complete documentation.

## Summary

In this lesson you learned:
- The `io.max` format: `MAJ:MIN rbps=X wbps=X riops=X wiops=X`
- How to find device major:minor numbers using `lsblk` or `/sys/block/*/dev`
- The difference between bandwidth limits (rbps/wbps) and IOPS limits (riops/wiops)
- How to verify I/O throttling using `dd` with direct I/O
- That I/O limits only work on block devices, not tmpfs or overlayfs

## Next

`05-pids.md` - Limit the number of processes in a cgroup to prevent fork bombs.
